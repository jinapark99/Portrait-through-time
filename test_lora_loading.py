#!/usr/bin/env python3
"""
ğŸ”§ LoRA ë¡œë”© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ LoRAë¥¼ ë¡œë”©í•´ì„œ ì–´ë–¤ ë°©ì‹ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import torch
import os
from diffusers import StableDiffusionImg2ImgPipeline
from peft import PeftModel

def test_lora_loading_methods():
    """ë‹¤ì–‘í•œ LoRA ë¡œë”© ë°©ë²•ì„ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ LoRA ë¡œë”© ë°©ë²• í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # M1 GPU ì„¤ì •
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"ğŸ“± ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    print("ğŸ¨ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16 if device in ["mps", "cuda"] else torch.float32,
        safety_checker=None,
        requires_safety_checker=False
    )
    pipe = pipe.to(device)
    
    # í…ŒìŠ¤íŠ¸í•  LoRA ê²½ë¡œë“¤
    lora_paths = [
        "lora_trained_model/final",
        "lora_trained_model/checkpoint-20",
        "lora_trained_model/checkpoint-15"
    ]
    
    for lora_path in lora_paths:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¤‘: {lora_path}")
        
        if not os.path.exists(lora_path):
            print(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {lora_path}")
            continue
        
        # ë°©ë²• 1: ê¸°ë³¸ load_lora_weights
        try:
            print("  ë°©ë²• 1: load_lora_weights() ì‹œë„...")
            pipe.load_lora_weights(lora_path)
            print("  âœ… ë°©ë²• 1 ì„±ê³µ!")
        except Exception as e:
            print(f"  âŒ ë°©ë²• 1 ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 2: weight_name ëª…ì‹œ
        try:
            print("  ë°©ë²• 2: weight_name ëª…ì‹œ ì‹œë„...")
            pipe.load_lora_weights(lora_path, weight_name="adapter_model.safetensors")
            print("  âœ… ë°©ë²• 2 ì„±ê³µ!")
        except Exception as e:
            print(f"  âŒ ë°©ë²• 2 ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 3: adapter_name ëª…ì‹œ
        try:
            print("  ë°©ë²• 3: adapter_name ëª…ì‹œ ì‹œë„...")
            pipe.load_lora_weights(lora_path, adapter_name="portrait_style")
            print("  âœ… ë°©ë²• 3 ì„±ê³µ!")
        except Exception as e:
            print(f"  âŒ ë°©ë²• 3 ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 4: PEFT ì§ì ‘ ì‚¬ìš©
        try:
            print("  ë°©ë²• 4: PEFT ì§ì ‘ ì‚¬ìš© ì‹œë„...")
            # UNetì— LoRA ì ìš©
            pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path)
            print("  âœ… ë°©ë²• 4 ì„±ê³µ!")
        except Exception as e:
            print(f"  âŒ ë°©ë²• 4 ì‹¤íŒ¨: {e}")
        
        # ë°©ë²• 5: íŒŒì¼ ì§ì ‘ ë¡œë“œ
        try:
            print("  ë°©ë²• 5: íŒŒì¼ ì§ì ‘ ë¡œë“œ ì‹œë„...")
            adapter_path = os.path.join(lora_path, "adapter_model.safetensors")
            if os.path.exists(adapter_path):
                pipe.load_lora_weights(adapter_path)
                print("  âœ… ë°©ë²• 5 ì„±ê³µ!")
            else:
                print("  âŒ adapter_model.safetensors íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"  âŒ ë°©ë²• 5 ì‹¤íŒ¨: {e}")
    
    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ì„±ê³µí•œ ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤...")

def test_actual_generation():
    """ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±ìœ¼ë¡œ LoRA ì ìš© í™•ì¸"""
    print("\nğŸ¨ ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸...")
    
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    
    # íŒŒì´í”„ë¼ì¸ ë¡œë“œ
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16 if device in ["mps", "cuda"] else torch.float32,
        safety_checker=None,
        requires_safety_checker=False
    )
    pipe = pipe.to(device)
    
    # LoRA ë¡œë“œ (ê°€ì¥ ì„±ê³µí•œ ë°©ë²• ì‚¬ìš©)
    lora_path = "lora_trained_model/final"
    try:
        pipe.load_lora_weights(lora_path)
        print(f"âœ… LoRA ë¡œë“œ ì„±ê³µ: {lora_path}")
    except Exception as e:
        print(f"âŒ LoRA ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
    from PIL import Image
    test_image = Image.open("IMG_5241.JPG").convert("RGB").resize((512, 512))
    
    # ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
    test_prompts = [
        "portrait painting, joyful expression",
        "medieval portrait, renaissance style, happy face",
        "classical portrait painting, cheerful expression",
        "portrait, contemplative expression, melancholic expression"
    ]
    
    for i, prompt in enumerate(test_prompts):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ {i+1}: {prompt}")
        
        try:
            result = pipe(
                prompt=prompt,
                image=test_image,
                strength=0.7,
                guidance_scale=7.5,
                num_inference_steps=10,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
                generator=torch.Generator(device=device)
            )
            
            output_path = f"lora_test_{i+1}.png"
            result.images[0].save(output_path)
            print(f"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_lora_loading_methods()
    test_actual_generation()





