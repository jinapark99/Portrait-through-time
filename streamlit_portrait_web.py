#!/usr/bin/env python3
"""
ğŸŒ ê°ì •ë³„ íšŒí™” ìŠ¤íƒ€ì¼ í¬íŠ¸ë ˆì´íŠ¸ ì›¹ ì„œë¹„ìŠ¤
Streamlitìœ¼ë¡œ ë§Œë“  ì›¹ ì•± - ì…€ì¹´ ì—…ë¡œë“œ â†’ ê°ì • ë¶„ì„ â†’ íšŒí™” ìŠ¤íƒ€ì¼ í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±
"""

import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
from diffusers import StableDiffusionImg2ImgPipeline
import mediapipe as mp
import io
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¨ ê°ì •ë³„ íšŒí™” ìŠ¤íƒ€ì¼ í¬íŠ¸ë ˆì´íŠ¸",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #A23B72;
        text-align: center;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 5px solid #28a745;
    }
    .processing-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 5px solid #ffc107;
    }
</style>
""", unsafe_allow_html=True)

class EmotionStylePortraitWeb:
    def __init__(self):
        # MediaPipe ì–¼êµ´ ê°ì§€ ì´ˆê¸°í™”
        self.mp_face_detection = mp.solutions.face_detection
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=0, min_detection_confidence=0.5
        )
        
        # ê°ì •ë³„ íšŒí™” ìŠ¤íƒ€ì¼ ì •ì˜
        self.emotion_styles = {
            "joyful": {
                "style": "renaissance portrait, bright and warm colors, golden lighting, cheerful expression, baroque style, vibrant colors, optimistic mood",
                "description": "ë¥´ë„¤ìƒìŠ¤/ë°”ë¡œí¬ ìŠ¤íƒ€ì¼ - ë°ê³  ë”°ëœ»í•œ ìƒ‰ì¡°",
                "emoji": "ğŸ˜Š"
            },
            "sad": {
                "style": "medieval portrait, dark and muted colors, melancholic expression, gothic style, somber mood, chiaroscuro lighting, contemplative",
                "description": "ì¤‘ì„¸/ê³ ë”• ìŠ¤íƒ€ì¼ - ì–´ë‘¡ê³  ì°¨ë¶„í•œ ìƒ‰ì¡°",
                "emoji": "ğŸ˜¢"
            },
            "angry": {
                "style": "baroque portrait, dramatic lighting, intense expression, bold colors, dynamic composition, powerful mood, dramatic shadows",
                "description": "ë°”ë¡œí¬ ìŠ¤íƒ€ì¼ - ë“œë¼ë§ˆí‹±í•˜ê³  ê°•ë ¬í•œ ìƒ‰ì¡°",
                "emoji": "ğŸ˜ "
            },
            "surprised": {
                "style": "rococo portrait, elegant and refined, soft pastel colors, delicate expression, ornate details, graceful mood, refined style",
                "description": "ë¡œì½”ì½” ìŠ¤íƒ€ì¼ - ìš°ì•„í•˜ê³  ì„¬ì„¸í•œ ìƒ‰ì¡°",
                "emoji": "ğŸ˜²"
            },
            "neutral": {
                "style": "classical portrait, balanced composition, natural colors, serene expression, timeless style, harmonious mood, classical proportions",
                "description": "í´ë˜ì‹ ìŠ¤íƒ€ì¼ - ê· í˜•ì¡íŒ ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ì¡°",
                "emoji": "ğŸ˜"
            },
            "contemplative": {
                "style": "romantic portrait, soft and dreamy colors, thoughtful expression, ethereal mood, soft lighting, introspective, romantic era style",
                "description": "ë‚­ë§Œì£¼ì˜ ìŠ¤íƒ€ì¼ - ë¶€ë“œëŸ½ê³  ëª½í™˜ì ì¸ ìƒ‰ì¡°",
                "emoji": "ğŸ¤”"
            }
        }
        
        self.pipe = None
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
    
    @st.cache_resource
    def load_model(_self):
        """ëª¨ë¸ ë¡œë“œ (ìºì‹œë¨)"""
        with st.spinner("ğŸ¨ AI ëª¨ë¸ ë¡œë“œ ì¤‘... (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            # Stable Diffusion íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                "runwayml/stable-diffusion-v1-5",
                torch_dtype=torch.float16 if _self.device in ["mps", "cuda"] else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            )
            pipe = pipe.to(_self.device)
            
            # LoRA ë¡œë“œ
            try:
                pipe.load_lora_weights("lora_trained_model/final")
                st.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ LoRA ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None
        
        return pipe
    
    def detect_face(self, image):
        """ì–¼êµ´ ê°ì§€ ë° ìì—°ìŠ¤ëŸ¬ìš´ í¬ë¡­"""
        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        results = self.face_detection.process(cv_image)
        
        if results.detections:
            detection = results.detections[0]
            bbox = detection.location_data.relative_bounding_box
            
            h, w, _ = cv_image.shape
            x = int(bbox.xmin * w)
            y = int(bbox.ymin * h)
            width = int(bbox.width * w)
            height = int(bbox.height * h)
            
            # ì–¼êµ´ ì¤‘ì‹¬ì  ê³„ì‚°
            face_center_x = x + width // 2
            face_center_y = y + height // 2
            
            # ìì—°ìŠ¤ëŸ¬ìš´ í¬ë¡­ì„ ìœ„í•´ ì–¼êµ´ í¬ê¸°ì˜ 2.5ë°°ë¡œ í™•ì¥
            crop_size = max(width, height) * 2.5
            
            # í¬ë¡­ ì˜ì—­ ê³„ì‚° (ì´ë¯¸ì§€ ê²½ê³„ ë‚´ì—ì„œ)
            crop_x = max(0, int(face_center_x - crop_size // 2))
            crop_y = max(0, int(face_center_y - crop_size // 2))
            crop_x2 = min(w, int(face_center_x + crop_size // 2))
            crop_y2 = min(h, int(face_center_y + crop_size // 2))
            
            # ìì—°ìŠ¤ëŸ¬ìš´ í¬ë¡­
            natural_crop = image.crop((crop_x, crop_y, crop_x2, crop_y2))
            return natural_crop, True
        else:
            return image, False
    
    def analyze_emotion_advanced(self, face_image):
        """ê³ ê¸‰ ê°ì • ë¶„ì„"""
        mp_face_mesh = mp.solutions.face_mesh
        face_mesh = mp_face_mesh.FaceMesh(
            static_image_mode=True,
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.3,
            min_tracking_confidence=0.3
        )
        
        img_array = np.array(face_image)
        results = face_mesh.process(img_array)
        
        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0]
            
            # ì–¼êµ´ íŠ¹ì§• ë¶„ì„
            left_corner = landmarks.landmark[61]
            right_corner = landmarks.landmark[291]
            mouth_curve = right_corner.y - left_corner.y
            
            left_eyebrow = landmarks.landmark[70]
            right_eyebrow = landmarks.landmark[300]
            eyebrow_height = (left_eyebrow.y + right_eyebrow.y) / 2
            
            left_eye = landmarks.landmark[33]
            right_eye = landmarks.landmark[7]
            eye_openness = abs(left_eye.y - right_eye.y)
            
            # ê°ì • íŒë‹¨
            if mouth_curve < -0.005 and eyebrow_height < 0.4:
                emotion = "joyful"
            elif mouth_curve > 0.01:
                emotion = "sad"
            elif eye_openness > 0.02 and eyebrow_height < 0.4:
                emotion = "surprised"
            elif eyebrow_height > 0.45 and mouth_curve < -0.002:
                emotion = "angry"
            elif eyebrow_height > 0.42:
                emotion = "contemplative"
            else:
                emotion = "neutral"
        else:
            # ì´ë¯¸ì§€ íŠ¹ì„±ìœ¼ë¡œ íŒë‹¨
            img_array = np.array(face_image)
            brightness = np.mean(img_array)
            
            if brightness < 80:
                emotion = "sad"
            elif brightness > 150:
                emotion = "joyful"
            else:
                emotion = "neutral"
        
        return emotion
    
    def create_portrait(self, image, emotion):
        """í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±"""
        if self.pipe is None:
            self.pipe = self.load_model()
        
        if self.pipe is None:
            return None
        
        # ì–¼êµ´ ê°ì§€
        face_crop, face_found = self.detect_face(image)
        input_image = face_crop.resize((512, 512))
        
        # ê°ì •ë³„ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
        style_prompt = self.emotion_styles[emotion]["style"]
        final_prompt = f"portrait painting, {style_prompt}"
        
        # ì´ë¯¸ì§€ ìƒì„± (ë” ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ìœ„í•´ strength ì¡°ì •)
        result = self.pipe(
            prompt=final_prompt,
            image=input_image,
            strength=0.4,  # ì›ë³¸ ì´ë¯¸ì§€ êµ¬ì¡°ë¥¼ ë” ë³´ì¡´
            guidance_scale=7.5,  # í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ë„ ì¡°ì •
            num_inference_steps=20,
            generator=torch.Generator(device=self.device)
        )
        
        return result.images[0]

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ¨ ê°ì •ë³„ íšŒí™” ìŠ¤íƒ€ì¼ í¬íŠ¸ë ˆì´íŠ¸</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ì…€ì¹´ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ê°ì •ì„ ë¶„ì„í•´ì„œ ë§ëŠ” íšŒí™” ìŠ¤íƒ€ì¼ë¡œ í¬íŠ¸ë ˆì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤!</p>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ­ ê°ì •ë³„ íšŒí™” ìŠ¤íƒ€ì¼")
        
        for emotion, info in EmotionStylePortraitWeb().emotion_styles.items():
            st.markdown(f"**{info['emoji']} {emotion.title()}**")
            st.markdown(f"*{info['description']}*")
            st.markdown("---")
        
        st.markdown("""
        ### ğŸ“ ì‚¬ìš©ë²•
        1. ì…€ì¹´ ì´ë¯¸ì§€ ì—…ë¡œë“œ
        2. AIê°€ ê°ì • ë¶„ì„
        3. ë§ëŠ” íšŒí™” ìŠ¤íƒ€ì¼ë¡œ í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±
        4. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        """)
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“¸ ì…€ì¹´ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            type=['jpg', 'jpeg', 'png'],
            help="ì–¼êµ´ì´ ëª…í™•íˆ ë³´ì´ëŠ” ì…€ì¹´ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
        )
        
        if uploaded_file is not None:
            # ì´ë¯¸ì§€ í‘œì‹œ
            image = Image.open(uploaded_file).convert("RGB")
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
            
            # ì²˜ë¦¬ ë²„íŠ¼
            if st.button("ğŸ¨ í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±í•˜ê¸°", type="primary"):
                with st.spinner("AIê°€ ê°ì •ì„ ë¶„ì„í•˜ê³  í¬íŠ¸ë ˆì´íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
                    generator = EmotionStylePortraitWeb()
                    
                    # ê°ì • ë¶„ì„
                    emotion = generator.analyze_emotion_advanced(image)
                    
                    # í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±
                    portrait = generator.create_portrait(image, emotion)
                    
                    if portrait:
                        with col2:
                            st.header("ğŸ¨ ìƒì„±ëœ í¬íŠ¸ë ˆì´íŠ¸")
                            
                            # ê°ì • ì •ë³´ í‘œì‹œ
                            emotion_info = generator.emotion_styles[emotion]
                            st.markdown(f"""
                            <div class="success-box">
                                <h3>{emotion_info['emoji']} ê°ì§€ëœ ê°ì •: {emotion.title()}</h3>
                                <p><strong>ì ìš©ëœ ìŠ¤íƒ€ì¼:</strong> {emotion_info['description']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # í¬íŠ¸ë ˆì´íŠ¸ í‘œì‹œ
                            st.image(portrait, caption="ìƒì„±ëœ í¬íŠ¸ë ˆì´íŠ¸", use_column_width=True)
                            
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            img_buffer = io.BytesIO()
                            portrait.save(img_buffer, format="PNG")
                            img_buffer.seek(0)
                            
                            st.download_button(
                                label="ğŸ“¥ í¬íŠ¸ë ˆì´íŠ¸ ë‹¤ìš´ë¡œë“œ",
                                data=img_buffer.getvalue(),
                                file_name=f"portrait_{emotion}_{int(time.time())}.png",
                                mime="image/png"
                            )
                    else:
                        st.error("âŒ í¬íŠ¸ë ˆì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666;">
        <p>ğŸ¨ AI ê°ì • ë¶„ì„ + íšŒí™” ìŠ¤íƒ€ì¼ í¬íŠ¸ë ˆì´íŠ¸ ìƒì„± ì„œë¹„ìŠ¤</p>
        <p>Powered by Stable Diffusion + LoRA + MediaPipe</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
