import os
import hashlib
import shutil
from collections import defaultdict

def get_file_hash(filepath):
    """íŒŒì¼ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    hash_md5 = hashlib.md5()
    try:
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except:
        return None

def remove_duplicate_images(folder_path):
    """ì¤‘ë³µëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤."""
    
    if not os.path.exists(folder_path):
        print(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return
    
    print(f"ğŸ” {folder_path}ì—ì„œ ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ê²€ì‚¬í•©ë‹ˆë‹¤...")
    
    # íŒŒì¼ í•´ì‹œë³„ë¡œ ê·¸ë£¹í™”
    hash_groups = defaultdict(list)
    file_hashes = {}
    
    # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì˜ í•´ì‹œ ê³„ì‚°
    image_files = [f for f in os.listdir(folder_path) 
                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]
    
    print(f"ğŸ“ ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ê²€ì‚¬í•©ë‹ˆë‹¤...")
    
    for filename in image_files:
        filepath = os.path.join(folder_path, filename)
        file_hash = get_file_hash(filepath)
        
        if file_hash:
            hash_groups[file_hash].append(filename)
            file_hashes[filename] = file_hash
            print(f"  âœ“ {filename} - í•´ì‹œ: {file_hash[:8]}...")
    
    # ì¤‘ë³µ íŒŒì¼ ì°¾ê¸°
    duplicates = {hash_val: files for hash_val, files in hash_groups.items() if len(files) > 1}
    
    if not duplicates:
        print("ğŸ‰ ì¤‘ë³µ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    print(f"\nğŸ” {len(duplicates)}ê°œì˜ ì¤‘ë³µ ê·¸ë£¹ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:")
    
    total_duplicates = 0
    removed_count = 0
    
    # ë°±ì—… í´ë” ìƒì„±
    backup_folder = os.path.join(folder_path, "duplicates_backup")
    os.makedirs(backup_folder, exist_ok=True)
    
    for hash_val, files in duplicates.items():
        print(f"\nğŸ“Š í•´ì‹œ {hash_val[:8]}... (ì¤‘ë³µ {len(files)}ê°œ):")
        for i, filename in enumerate(files):
            print(f"  {i+1}. {filename}")
        
        # ì²« ë²ˆì§¸ íŒŒì¼ì€ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” ë°±ì—…ìœ¼ë¡œ ì´ë™
        keep_file = files[0]
        duplicate_files = files[1:]
        
        print(f"  âœ… ìœ ì§€: {keep_file}")
        
        for dup_file in duplicate_files:
            source_path = os.path.join(folder_path, dup_file)
            backup_path = os.path.join(backup_folder, dup_file)
            
            try:
                shutil.move(source_path, backup_path)
                print(f"  ğŸ—‘ï¸ ë°±ì—…ìœ¼ë¡œ ì´ë™: {dup_file}")
                removed_count += 1
            except Exception as e:
                print(f"  âŒ ì´ë™ ì‹¤íŒ¨: {dup_file} - {e}")
        
        total_duplicates += len(duplicate_files)
    
    print(f"\nğŸ‰ === ì¤‘ë³µ ì œê±° ì™„ë£Œ ===")
    print(f"âœ… ìœ ì§€ëœ íŒŒì¼: {len(image_files) - total_duplicates}ê°œ")
    print(f"ğŸ—‘ï¸ ì œê±°ëœ ì¤‘ë³µ: {removed_count}ê°œ")
    print(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {backup_folder}")
    
    return removed_count

def analyze_remaining_images(folder_path):
    """ë‚¨ì€ ì´ë¯¸ì§€ë“¤ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    if not os.path.exists(folder_path):
        return
    
    image_files = [f for f in os.listdir(folder_path) 
                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]
    
    print(f"\nğŸ“Š === ë‚¨ì€ ì´ë¯¸ì§€ ë¶„ì„ ===")
    print(f"ğŸ“ ì´ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
    
    # íŒŒì¼ í¬ê¸°ë³„ ë¶„ì„
    size_groups = {
        'small (< 1MB)': 0,
        'medium (1-5MB)': 0,
        'large (> 5MB)': 0
    }
    
    total_size = 0
    
    for filename in image_files:
        filepath = os.path.join(folder_path, filename)
        try:
            size = os.path.getsize(filepath)
            total_size += size
            
            if size < 1024 * 1024:  # < 1MB
                size_groups['small (< 1MB)'] += 1
            elif size < 5 * 1024 * 1024:  # < 5MB
                size_groups['medium (1-5MB)'] += 1
            else:  # >= 5MB
                size_groups['large (> 5MB)'] += 1
                
        except:
            pass
    
    print(f"\nğŸ“ íŒŒì¼ í¬ê¸°ë³„ ë¶„í¬:")
    for size_group, count in size_groups.items():
        print(f"  â€¢ {size_group}: {count}ê°œ")
    
    print(f"\nğŸ’¾ ì´ ìš©ëŸ‰: {total_size / (1024*1024):.1f}MB")

def main():
    print("ğŸ§¹ ì¤‘ë³µ ì´ë¯¸ì§€ ì œê±° ë„êµ¬")
    print("=" * 50)
    
    # CSV í¬íŠ¸ë ˆì´íŠ¸ í´ë”ì—ì„œ ì¤‘ë³µ ì œê±°
    csv_folder = "data/csv_portraits"
    
    if os.path.exists(csv_folder):
        removed_count = remove_duplicate_images(csv_folder)
        analyze_remaining_images(csv_folder)
        
        if removed_count > 0:
            print(f"\nğŸ’¡ íŒ:")
            print(f"â€¢ ì¤‘ë³µëœ íŒŒì¼ë“¤ì€ {csv_folder}/duplicates_backup/ í´ë”ë¡œ ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤")
            print(f"â€¢ í•„ìš”í•˜ë©´ ì–¸ì œë“ ì§€ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    else:
        print(f"âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_folder}")

if __name__ == "__main__":
    main()
