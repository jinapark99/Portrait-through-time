import os
import requests
import pandas as pd
import time
import json
import random

# ì„¤ì •
SAVE_DIR = "data/department_portraits"
METADATA_DIR = "data/department_metadata"
os.makedirs(SAVE_DIR, exist_ok=True)
os.makedirs(METADATA_DIR, exist_ok=True)

# ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë¯¸ìˆ ê´€ API ì„¤ì •
MET_API_BASE = "https://collectionapi.metmuseum.org/public/collection/v1"

# User-Agent ë¦¬ìŠ¤íŠ¸
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
]

def get_random_user_agent():
    return random.choice(USER_AGENTS)

def human_delay():
    """ì¸ê°„ì ì¸ ì§€ì—°"""
    delay = random.uniform(3.0, 6.0)
    time.sleep(delay)

def get_department_objects(department_id, limit=5000):
    """íŠ¹ì • ë¶€ì„œì˜ ëª¨ë“  ì‘í’ˆ ID ê°€ì ¸ì˜¤ê¸°"""
    
    print(f"ğŸ›ï¸ {department_id} ë¶€ì„œì˜ ì‘í’ˆë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    
    try:
        # ë¶€ì„œë³„ ê²€ìƒ‰
        search_url = f"{MET_API_BASE}/search"
        params = {
            'departmentId': department_id,
            'hasImages': 'true',
            'isHighlight': 'false'
        }
        
        headers = {'User-Agent': get_random_user_agent()}
        response = requests.get(search_url, params=params, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            object_ids = data.get('objectIDs', [])[:limit]
            print(f"  âœ… {len(object_ids)}ê°œ ì‘í’ˆ ë°œê²¬")
            return object_ids
        else:
            print(f"  âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code}")
            return []
            
    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜: {e}")
        return []

def get_object_details(object_id):
    """ì‘í’ˆ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        detail_url = f"{MET_API_BASE}/objects/{object_id}"
        headers = {'User-Agent': get_random_user_agent()}
        response = requests.get(detail_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except Exception as e:
        return None

def is_portrait_advanced(obj_data):
    """ê³ ê¸‰ ì´ˆìƒí™” íŒë‹¨ ë¡œì§"""
    if not obj_data:
        return False
    
    # í…ìŠ¤íŠ¸ í•„ë“œë“¤ ìˆ˜ì§‘
    text_fields = [
        obj_data.get('title', ''),
        obj_data.get('classification', ''),
        obj_data.get('objectName', ''),
        obj_data.get('department', ''),
        obj_data.get('culture', ''),
        obj_data.get('period', ''),
        obj_data.get('medium', ''),
        obj_data.get('artistDisplayName', '')
    ]
    
    combined_text = ' '.join(text_fields).lower()
    
    # í¬ê´„ì ì¸ ì´ˆìƒí™” í‚¤ì›Œë“œë“¤
    portrait_keywords = [
        # ê¸°ë³¸ í‚¤ì›Œë“œ
        'portrait', 'portraiture', 'self-portrait', 'self portrait',
        'bust', 'head', 'figure', 'profile',
        'likeness', 'representation', 'image of',
        
        # êµ¬ì²´ì ì¸ í‘œí˜„ë“¤
        'portrait of', 'portrait of a', 'portrait of the',
        'head of', 'bust of', 'figure of',
        
        # ì¸ë¬¼ ê´€ë ¨
        'man', 'woman', 'lady', 'gentleman', 'person', 'people',
        'child', 'boy', 'girl', 'infant', 'baby',
        'elderly', 'old man', 'old woman',
        
        # ì§ì—…/ì‹ ë¶„
        'king', 'queen', 'prince', 'princess', 'emperor', 'empress',
        'noble', 'nobleman', 'noblewoman', 'aristocrat',
        'monk', 'nun', 'priest', 'bishop', 'cardinal',
        'merchant', 'banker', 'scholar', 'artist', 'painter',
        
        # ìí™”ìƒ ê´€ë ¨
        'autoportrait', 'autoritratto', 'selbstportrait',
        
        # ê¸°íƒ€ í‘œí˜„ë“¤
        'effigy', 'statue', 'sculpture of', 'painting of'
    ]
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
    keyword_matches = sum(1 for keyword in portrait_keywords if keyword in combined_text)
    
    # ìµœì†Œ 1ê°œ ì´ìƒì˜ í‚¤ì›Œë“œ ë§¤ì¹­ í•„ìš”
    if keyword_matches == 0:
        return False
    
    # ì œì™¸í•  í‚¤ì›Œë“œë“¤ (ì´ˆìƒí™”ê°€ ì•„ë‹Œ ê²½ìš°)
    exclude_keywords = [
        'landscape', 'still life', 'still-life', 'nature', 'flower',
        'animal', 'architecture', 'building', 'interior', 'exterior',
        'mythology', 'mythological', 'allegory', 'allegorical',
        'battle', 'war', 'scene', 'event', 'story'
    ]
    
    # ì œì™¸ í‚¤ì›Œë“œê°€ ë§ì´ í¬í•¨ë˜ë©´ ì œì™¸
    exclude_matches = sum(1 for keyword in exclude_keywords if keyword in combined_text)
    
    # ì œì™¸ í‚¤ì›Œë“œê°€ ë§ìœ¼ë©´ ì´ˆìƒí™”ê°€ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
    if exclude_matches > 2:
        return False
    
    # ìµœì¢… íŒë‹¨: í‚¤ì›Œë“œ ë§¤ì¹­ì´ ìˆê³  ì œì™¸ í‚¤ì›Œë“œê°€ ì ìœ¼ë©´ ì´ˆìƒí™”
    return keyword_matches > 0 and exclude_matches <= 2

def download_image(url, filename):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        headers = {
            'User-Agent': get_random_user_agent(),
            'Accept': 'image/*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        response = requests.get(url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            filepath = os.path.join(SAVE_DIR, filename)
            with open(filepath, 'wb') as f:
                f.write(response.content)
            return filepath
        else:
            return None
    except Exception as e:
        return None

def scan_department_for_portraits(department_name, department_id, limit=1000):
    """ë¶€ì„œë³„ ì´ˆìƒí™” ìŠ¤ìº”"""
    
    print(f"\nğŸ›ï¸ === {department_name} ë¶€ì„œ ì´ˆìƒí™” ìŠ¤ìº” ===")
    
    # 1ë‹¨ê³„: ë¶€ì„œì˜ ëª¨ë“  ì‘í’ˆ ID ê°€ì ¸ì˜¤ê¸°
    object_ids = get_department_objects(department_id, limit)
    
    if not object_ids:
        print(f"âŒ {department_name} ë¶€ì„œì—ì„œ ì‘í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # 2ë‹¨ê³„: ê° ì‘í’ˆ ë¶„ì„ ë° ì´ˆìƒí™” ë‹¤ìš´ë¡œë“œ
    downloaded_count = 0
    failed_count = 0
    not_portrait_count = 0
    api_error_count = 0
    results = []
    
    print(f"\nğŸ“¥ {len(object_ids)}ê°œ ì‘í’ˆì„ ë¶„ì„í•©ë‹ˆë‹¤...")
    
    for i, object_id in enumerate(object_ids):
        print(f"\n[{i+1}/{len(object_ids)}] ë¶„ì„ ì¤‘: ID {object_id}")
        
        # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        obj_data = get_object_details(object_id)
        
        if not obj_data:
            print(f"  âŒ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
            api_error_count += 1
            if api_error_count > 10:
                print(f"  ğŸ˜´ API ì˜¤ë¥˜ê°€ ë§ì•„ 30ì´ˆ íœ´ì‹...")
                time.sleep(30)
                api_error_count = 0
            continue
        
        # ê³ ê¸‰ ì´ˆìƒí™” íŒë‹¨
        if not is_portrait_advanced(obj_data):
            print(f"  â­ï¸ ì´ˆìƒí™”ê°€ ì•„ë‹˜ - ê±´ë„ˆëœ€")
            not_portrait_count += 1
            continue
        
        # ì´ë¯¸ì§€ URL í™•ì¸
        image_url = obj_data.get('primaryImage')
        if not image_url or not image_url.strip():
            print(f"  âŒ ì´ë¯¸ì§€ URL ì—†ìŒ")
            failed_count += 1
            continue
        
        # ì‘í’ˆ ì •ë³´ ì¶œë ¥
        title = obj_data.get('title', 'Untitled')
        artist = obj_data.get('artistDisplayName', 'Unknown')
        print(f"  ğŸ¨ {artist} - {title}")
        
        # íŒŒì¼ëª… ìƒì„±
        import re
        title_clean = re.sub(r'[^\w\s\-]', '', title)[:50].replace(' ', '_')
        artist_clean = re.sub(r'[^\w\s\-]', '', artist)[:30].replace(' ', '_')
        filename = f"{department_id}_{object_id}_{artist_clean}_{title_clean}.jpg"
        
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        filepath = download_image(image_url, filename)
        
        if filepath:
            file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
            print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} ({file_size_mb:.1f}MB)")
            
            downloaded_count += 1
            results.append({
                'department_id': department_id,
                'department_name': department_name,
                'object_id': object_id,
                'title': title,
                'artist': artist,
                'image_url': image_url,
                'filename': filename,
                'filepath': filepath,
                'file_size_mb': file_size_mb,
                'classification': obj_data.get('classification', ''),
                'culture': obj_data.get('culture', ''),
                'period': obj_data.get('period', ''),
                'medium': obj_data.get('medium', ''),
                'object_date': obj_data.get('objectDate', ''),
                'status': 'success'
            })
        else:
            print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {title}")
            failed_count += 1
        
        # ì¸ê°„ì ì¸ ì§€ì—°
        human_delay()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ (ë§¤ 50ê°œë§ˆë‹¤)
        if (i + 1) % 50 == 0:
            print(f"\nğŸ“Š ì§„í–‰ ìƒí™©: {i+1:,}/{len(object_ids):,} ì™„ë£Œ")
            print(f"  âœ… ì„±ê³µ: {downloaded_count:,}ê°œ")
            print(f"  âŒ ì‹¤íŒ¨: {failed_count:,}ê°œ")
            print(f"  â­ï¸ ì´ˆìƒí™” ì•„ë‹˜: {not_portrait_count:,}ê°œ")
            print(f"  ğŸš« API ì˜¤ë¥˜: {api_error_count:,}ê°œ")
            print(f"  ğŸ“ˆ ì„±ê³µë¥ : {(downloaded_count/(i+1)*100):.1f}%")
    
    print(f"\nğŸ‰ === {department_name} ë¶€ì„œ ìŠ¤ìº” ì™„ë£Œ ===")
    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {downloaded_count}ê°œ")
    print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"â­ï¸ ì´ˆìƒí™” ì•„ë‹˜: {not_portrait_count}ê°œ")
    print(f"ğŸš« API ì˜¤ë¥˜: {api_error_count}ê°œ")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬: {len(object_ids)}ê°œ")
    
    return results

def main():
    print("ğŸ›ï¸ ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë¯¸ìˆ ê´€ ë¶€ì„œë³„ ì´ˆìƒí™” ìŠ¤ìº”")
    print("ê°€ì¥ ì •í™•ë„ ë†’ì€ ë°©ë²•ìœ¼ë¡œ ì´ˆìƒí™”ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤!")
    print("=" * 60)
    
    # ì´ˆìƒí™”ê°€ ë§ì€ ì£¼ìš” ë¶€ì„œë“¤
    departments = [
        {
            'id': 11,  # European Paintings
            'name': 'European Paintings'
        },
        {
            'id': 1,   # American Paintings and Sculpture
            'name': 'American Paintings and Sculpture'
        },
        {
            'id': 21,  # Modern and Contemporary Art
            'name': 'Modern and Contemporary Art'
        },
        {
            'id': 2,   # The American Wing
            'name': 'The American Wing'
        }
    ]
    
    all_results = []
    
    for dept in departments:
        # ê° ë¶€ì„œë³„ë¡œ ìŠ¤ìº”
        results = scan_department_for_portraits(
            dept['name'], 
            dept['id'], 
            limit=500  # ê° ë¶€ì„œë‹¹ 500ê°œì”© í…ŒìŠ¤íŠ¸
        )
        all_results.extend(results)
        
        # ë¶€ì„œ ê°„ ì§€ì—°
        print(f"\nğŸ˜´ ë‹¤ìŒ ë¶€ì„œë¡œ ë„˜ì–´ê°€ê¸° ì „ 60ì´ˆ íœ´ì‹...")
        time.sleep(60)
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    if all_results:
        results_df = pd.DataFrame(all_results)
        results_df.to_csv(os.path.join(METADATA_DIR, "department_portraits_results.csv"), index=False, encoding='utf-8')
        
        print(f"\nğŸ‰ === ì „ì²´ ë¶€ì„œë³„ ìŠ¤ìº” ì™„ë£Œ ===")
        print(f"âœ… ì´ ë‹¤ìš´ë¡œë“œ: {len(all_results)}ê°œ")
        print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥: {SAVE_DIR}")
        print(f"ğŸ“„ ë©”íƒ€ë°ì´í„°: {METADATA_DIR}/department_portraits_results.csv")
        
        # ë¶€ì„œë³„ í†µê³„
        dept_stats = results_df.groupby('department_name').size()
        print(f"\nğŸ“Š ë¶€ì„œë³„ ì‘í’ˆ ìˆ˜:")
        for dept, count in dept_stats.items():
            print(f"  â€¢ {dept}: {count}ê°œ")
    else:
        print(f"\nâŒ ë‹¤ìš´ë¡œë“œëœ ì´ˆìƒí™”ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
