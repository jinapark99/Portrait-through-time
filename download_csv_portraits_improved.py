import os
import requests
import pandas as pd
import time
import re
from urllib.parse import quote

# ì„¤ì •
CSV_FILE = "portraits_dataset.csv"
SAVE_DIR = "data/csv_portraits_improved"
os.makedirs(SAVE_DIR, exist_ok=True)

# ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë¯¸ìˆ ê´€ API ì„¤ì •
MET_API_BASE = "https://collectionapi.metmuseum.org/public/collection/v1"

def create_detailed_search_query(title, medium, classification):
    """ì œëª©, ì¬ë£Œ, ë¶„ë¥˜ë¥¼ ëª¨ë‘ í¬í•¨í•œ ìƒì„¸ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ì¡°í•©
    search_terms = []
    
    # ì œëª© ì¶”ê°€
    if title:
        search_terms.append(title)
    
    # ì¬ë£Œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    if medium:
        medium_keywords = []
        if 'oil' in medium.lower():
            medium_keywords.append('oil')
        if 'canvas' in medium.lower():
            medium_keywords.append('canvas')
        if 'panel' in medium.lower():
            medium_keywords.append('panel')
        if 'paper' in medium.lower():
            medium_keywords.append('paper')
        if 'bronze' in medium.lower():
            medium_keywords.append('bronze')
        if 'etching' in medium.lower():
            medium_keywords.append('etching')
        if 'lithograph' in medium.lower():
            medium_keywords.append('lithograph')
        if 'photograph' in medium.lower():
            medium_keywords.append('photograph')
        
        search_terms.extend(medium_keywords)
    
    # ë¶„ë¥˜ ì¶”ê°€
    if classification:
        search_terms.append(classification.lower())
    
    # ì¤‘ë³µ ì œê±°í•˜ê³  ì¡°í•©
    unique_terms = list(set(search_terms))
    return ' '.join(unique_terms)

def search_met_portrait_detailed(title, medium, classification, limit=3):
    """ìƒì„¸ ê²€ìƒ‰ìœ¼ë¡œ ë©”íŠ¸ë¡œí´ë¦¬íƒ„ ë¯¸ìˆ ê´€ì—ì„œ ì´ˆìƒí™” ê²€ìƒ‰"""
    try:
        # ìƒì„¸ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = create_detailed_search_query(title, medium, classification)
        print(f"  ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{search_query}'")
        
        # ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        search_url = f"{MET_API_BASE}/search"
        params = {
            'q': search_query,
            'hasImages': 'true',
            'isHighlight': 'false'
        }
        
        response = requests.get(search_url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            object_ids = data.get('objectIDs', [])[:limit]
            
            portraits = []
            for obj_id in object_ids:
                # ê° ì‘í’ˆì˜ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                detail_url = f"{MET_API_BASE}/objects/{obj_id}"
                detail_response = requests.get(detail_url, timeout=10)
                
                if detail_response.status_code == 200:
                    obj_data = detail_response.json()
                    
                    # ì´ˆìƒí™” ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
                    title_lower = obj_data.get('title', '').lower()
                    classification_lower = obj_data.get('classification', '').lower()
                    object_name = obj_data.get('objectName', '').lower()
                    department = obj_data.get('department', '').lower()
                    
                    # ì´ˆìƒí™” ê´€ë ¨ í‚¤ì›Œë“œë“¤
                    portrait_keywords = ['portrait', 'portraiture', 'self-portrait', 'bust', 'head', 'figure']
                    
                    if any(keyword in title_lower or keyword in classification_lower or keyword in object_name 
                           for keyword in portrait_keywords):
                        
                        # ì´ë¯¸ì§€ URL ì°¾ê¸°
                        primary_image = obj_data.get('primaryImage')
                        if primary_image and primary_image.strip():
                            portraits.append({
                                'title': obj_data.get('title', ''),
                                'artist': obj_data.get('artistDisplayName', ''),
                                'image_url': primary_image,
                                'object_id': obj_id,
                                'culture': obj_data.get('culture', ''),
                                'period': obj_data.get('period', ''),
                                'medium': obj_data.get('medium', ''),
                                'department': obj_data.get('department', ''),
                                'object_date': obj_data.get('objectDate', ''),
                                'classification': obj_data.get('classification', '')
                            })
                
                time.sleep(0.3)  # API í˜¸ì¶œ ì œí•œ
            
            return portraits
    except Exception as e:
        print(f"  âŒ ê²€ìƒ‰ ì˜¤ë¥˜ ({search_query}): {e}")
        return []

def download_image(url, filename):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; PortraitDownloader/1.0)',
            'Accept': 'image/*'
        }
        response = requests.get(url, headers=headers, timeout=20)
        
        if response.status_code == 200:
            filepath = os.path.join(SAVE_DIR, filename)
            with open(filepath, 'wb') as f:
                f.write(response.content)
            return filepath
        else:
            print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def process_csv_portraits_improved():
    """ê°œì„ ëœ ë°©ì‹ìœ¼ë¡œ CSV íŒŒì¼ì˜ ì´ˆìƒí™”ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(CSV_FILE)
    print(f"ğŸ“‹ CSV íŒŒì¼ì—ì„œ {len(df)}ê°œì˜ ì´ˆìƒí™” ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    downloaded_count = 0
    failed_count = 0
    no_match_count = 0
    duplicate_count = 0
    results = []
    
    # ì²˜ìŒ 20ê°œë§Œ í…ŒìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ (ì „ì²´ ì²˜ë¦¬í•˜ë ¤ë©´ ì´ ì¤„ì„ ì œê±°í•˜ì„¸ìš”)
    df_sample = df.head(20).copy()
    print(f"ğŸ” ì²˜ìŒ {len(df_sample)}ê°œ ì‘í’ˆì„ í…ŒìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ URLë“¤ì„ ì¶”ì  (ì¤‘ë³µ ë°©ì§€)
    downloaded_urls = set()
    
    for idx, row in df_sample.iterrows():
        title = row.get('Title', '').strip()
        medium = row.get('Medium', '').strip()
        classification = row.get('Classification', '').strip()
        
        if not title:
            continue
            
        print(f"\n[{idx+1}/{len(df_sample)}] ì²˜ë¦¬ ì¤‘: '{title}'")
        print(f"  ğŸ“ ì¬ë£Œ: {medium}")
        print(f"  ğŸ“‚ ë¶„ë¥˜: {classification}")
        
        # ìƒì„¸ ê²€ìƒ‰
        portraits = search_met_portrait_detailed(title, medium, classification)
        
        if portraits:
            # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” ì´ˆìƒí™” ì„ íƒ
            portrait = portraits[0]
            
            # ì¤‘ë³µ URL ì²´í¬
            if portrait['image_url'] in downloaded_urls:
                print(f"  âš ï¸ ì¤‘ë³µ ì´ë¯¸ì§€ ë°œê²¬ - ê±´ë„ˆëœ€")
                duplicate_count += 1
                results.append({
                    'csv_index': idx,
                    'csv_title': title,
                    'csv_medium': medium,
                    'csv_classification': classification,
                    'found_title': portrait['title'],
                    'found_artist': portrait['artist'],
                    'filepath': '',
                    'status': 'duplicate_skipped'
                })
                continue
            
            # íŒŒì¼ëª… ìƒì„±
            artist_name = re.sub(r"[^\w\s\-]", "", portrait['artist'])[:25].replace(" ", "_")
            title_name = re.sub(r"[^\w\s\-]", "", portrait['title'])[:25].replace(" ", "_")
            medium_short = re.sub(r"[^\w\s\-]", "", medium)[:15].replace(" ", "_")
            filename = f"{idx:04d}_{artist_name}_{title_name}_{medium_short}.jpg"
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            filepath = download_image(portrait['image_url'], filename)
            
            if filepath:
                print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                downloaded_count += 1
                downloaded_urls.add(portrait['image_url'])  # URL ê¸°ë¡
                results.append({
                    'csv_index': idx,
                    'csv_title': title,
                    'csv_medium': medium,
                    'csv_classification': classification,
                    'found_title': portrait['title'],
                    'found_artist': portrait['artist'],
                    'filepath': filepath,
                    'object_id': portrait['object_id'],
                    'culture': portrait['culture'],
                    'period': portrait['period'],
                    'medium_found': portrait['medium'],
                    'department': portrait['department'],
                    'classification_found': portrait['classification'],
                    'status': 'success'
                })
            else:
                print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {title}")
                failed_count += 1
        else:
            print(f"  ğŸ” ë§¤ì¹­ë˜ëŠ” ì´ˆìƒí™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {title}")
            no_match_count += 1
            results.append({
                'csv_index': idx,
                'csv_title': title,
                'csv_medium': medium,
                'csv_classification': classification,
                'found_title': '',
                'found_artist': '',
                'filepath': '',
                'status': 'no_match'
            })
        
        # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
        time.sleep(1)
    
    # ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame(results)
    results_df.to_csv("csv_portraits_improved_results.csv", index=False, encoding='utf-8')
    
    print(f"\nğŸ‰ === ê°œì„ ëœ ì²˜ë¦¬ ì™„ë£Œ ===")
    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {downloaded_count}ê°œ")
    print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"ğŸ” ë§¤ì¹­ ì—†ìŒ: {no_match_count}ê°œ")
    print(f"âš ï¸ ì¤‘ë³µ ê±´ë„ˆëœ€: {duplicate_count}ê°œ")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬: {len(df_sample)}ê°œ")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: csv_portraits_improved_results.csv")
    print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {SAVE_DIR}")
    
    return results_df

def analyze_improved_results(results_df):
    """ê°œì„ ëœ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    if len(results_df) == 0:
        print("ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“Š === ê°œì„ ëœ ê²°ê³¼ ë¶„ì„ ===")
    
    # ìƒíƒœë³„ í†µê³„
    status_counts = results_df['status'].value_counts()
    print(f"\nğŸ“ˆ ìƒíƒœë³„ í†µê³„:")
    for status, count in status_counts.items():
        print(f"  â€¢ {status}: {count}ê°œ")
    
    # ì„±ê³µí•œ ì‘í’ˆë“¤ì˜ ì •ë³´
    successful = results_df[results_df['status'] == 'success']
    if len(successful) > 0:
        print(f"\nğŸ¨ ì„±ê³µí•œ ì‘í’ˆë“¤:")
        for _, row in successful.iterrows():
            print(f"  â€¢ {row['found_artist']} - {row['found_title']}")
            print(f"    CSV: {row['csv_title']} ({row['csv_medium']})")
            print(f"    Found: {row['found_title']} ({row['medium_found']})")
            print()
        
        # ì¬ë£Œë³„ í†µê³„
        medium_counts = successful['csv_medium'].value_counts()
        print(f"\nğŸ¨ CSV ì¬ë£Œë³„ ì‘í’ˆ ìˆ˜:")
        for medium, count in medium_counts.head(10).items():
            print(f"  â€¢ {medium}: {count}ê°œ")

def main():
    print("ğŸ¨ ê°œì„ ëœ CSV ì´ˆìƒí™” ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë”")
    print("ì œëª© + ì¬ë£Œ + ë¶„ë¥˜ë¥¼ ëª¨ë‘ ê³ ë ¤í•œ ìƒì„¸ ê²€ìƒ‰ìœ¼ë¡œ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤!")
    print("=" * 70)
    
    # CSV ì²˜ë¦¬
    results_df = process_csv_portraits_improved()
    
    # ê²°ê³¼ ë¶„ì„
    analyze_improved_results(results_df)
    
    print(f"\nğŸ’¡ ê°œì„  ì‚¬í•­:")
    print(f"â€¢ ì œëª© + ì¬ë£Œ + ë¶„ë¥˜ë¥¼ ëª¨ë‘ í¬í•¨í•œ ìƒì„¸ ê²€ìƒ‰")
    print(f"â€¢ ì¤‘ë³µ URL ìë™ ê°ì§€ ë° ê±´ë„ˆë›°ê¸°")
    print(f"â€¢ íŒŒì¼ëª…ì— ì¬ë£Œ ì •ë³´ í¬í•¨")
    print(f"â€¢ ë” ì •í™•í•œ ì‘í’ˆ ë§¤ì¹­")

if __name__ == "__main__":
    main()
